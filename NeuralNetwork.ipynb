{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetwork.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "5vGUuZVryu66",
        "ni5unOo55IY9",
        "RhoPPFuKzhms",
        "ZKjpIWheznli",
        "WpmyWFLT0hwC",
        "OcuElBr404JD",
        "UqkzoHYu95sE",
        "2lYqxVgVKO2o"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "WD2FGwLByqal",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Introdução ao PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "5vGUuZVryu66",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Instalação"
      ]
    },
    {
      "metadata": {
        "id": "ULhPFRO_DfUe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "\n",
        "\n",
        "\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "\n",
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ni5unOo55IY9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Carregado helpers"
      ]
    },
    {
      "metadata": {
        "id": "qzlODZ3u5LTr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Funções retirada do curso \"Pytorch Schorlarship Chalenge\" da Udacity e Facebook \"\"\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def test_network(net, trainloader):\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # Create Variables for the inputs and targets\n",
        "    inputs = Variable(images)\n",
        "    targets = Variable(images)\n",
        "\n",
        "    # Clear the gradients from all Variables\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass, then backward pass, then update weights\n",
        "    output = net.forward(inputs)\n",
        "    loss = criterion(output, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def view_recon(img, recon):\n",
        "    ''' Function for displaying an image (as a PyTorch Tensor) and its\n",
        "        reconstruction also a PyTorch Tensor\n",
        "    '''\n",
        "\n",
        "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
        "    axes[0].imshow(img.numpy().squeeze())\n",
        "    axes[1].imshow(recon.data.numpy().squeeze())\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "        ax.set_adjustable('box-forced')\n",
        "\n",
        "        \n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RhoPPFuKzhms",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Usando torch para criar Tensores"
      ]
    },
    {
      "metadata": {
        "id": "ND06nQsu5Mrj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(torch.randn(2,2,requires_grad=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZKjpIWheznli",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Definindo função Sigmoid"
      ]
    },
    {
      "metadata": {
        "id": "8BZyLSY8G8BW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Definindo uma função sigmoid com Numpy\n",
        "def sigmoid(z):\n",
        "  return 1/(1 + np.exp(-z))\n",
        "\n",
        "\n",
        "#Rodando a função sigmoid de 1 e de numpy arrays\n",
        "s1 = sigmoid(1)\n",
        "s2 = sigmoid(np.array([-1,0,1]))\n",
        "\n",
        "print(s1)\n",
        "print(s2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WpmyWFLT0hwC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Rede neural com Numpy"
      ]
    },
    {
      "metadata": {
        "id": "hq-S1UEPEa73",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "  def __init__(self):\n",
        "    self.inputLayerSize = 2\n",
        "    self.hiddenLayerSize = 3\n",
        "    self.outputLayerSize = 1\n",
        "    \n",
        "    self.W1 = np.random.randn(self.inputLayerSize, self.hiddenLayerSize)\n",
        "    self.W2 = np.random.randn(self.hiddenLayerSize, self.outputLayerSize)\n",
        "    \n",
        "  #Propagate a matrix X\n",
        "  def forward(self, X):\n",
        "    self.z2 =np.dot(X, self.W1)\n",
        "    self.a2 = sigmoid(self.z2)\n",
        "    self.z3 = np.dot(self.a2, self.W2)\n",
        "    yHat = sigmoid(self.z3)\n",
        "    return yHat\n",
        "  \n",
        "  def sigmoidPrime(z):\n",
        "    #Derivative of sigmoid function\n",
        "    return np.exp(-z)/((1+np.exp(-z))**2)\n",
        "  \n",
        "  def costFunctionPrime(self, X, y):\n",
        "    self.yHat = self.forward(X)\n",
        "    \n",
        "    delta3 = np.multiply(-(y- self.yHat), self.sigmoidPrime(self.z3))\n",
        "    dJdW2 = np.dot(self.a2.T, delta3)\n",
        "\n",
        "    delta2 = np.dot(delta3, self.W2.T) *self.sigmoidPrime(self.z2)\n",
        "    dJsW1 = np.dot(X.T,delta2)\n",
        "\n",
        "    return dJdW1, dJdW2\n",
        "    \n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0htoqRorWP-x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NN =NeuralNetwork()\n",
        "\n",
        "\n",
        "X = np.random.randn(NN.hiddenLayerSize,NN.inputLayerSize)\n",
        "y = np.random.randn(NN.hiddenLayerSize,1)\n",
        "print(X.shape)\n",
        "yHat= NN.forward(X)\n",
        "\n",
        "print(yHat)\n",
        "\n",
        "\n",
        "\n",
        "NN2 = NeuralNetwork()\n",
        "print(NN2)\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OcuElBr404JD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Redes neurais com PyTorch\n"
      ]
    },
    {
      "metadata": {
        "id": "MKOR8AXf1RiF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "#Usando nn.Module\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.hidden = nn.Linear(784, 256)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.output = nn.Linear(256, 10)\n",
        "        \n",
        "        # Define sigmoid activation and softmax output \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Pass the input tensor through each of our operations\n",
        "        x = self.hidden(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.output(x)\n",
        "        x = self.softmax(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    \n",
        "net = Network()\n",
        "print('net:',net1)\n",
        "\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NetworkF(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.hidden = nn.Linear(784, 256)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.output = nn.Linear(256, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Hidden layer with sigmoid activation\n",
        "        x = F.sigmoid(self.hidden(x))\n",
        "        # Output layer with softmax activation\n",
        "        x = F.softmax(self.output(x), dim=1)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "netF = NetworkF()\n",
        "print('netF:',netF)\n",
        "\n",
        "\n",
        "nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        " \n",
        "print('netS:',netS)\n",
        "      \n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HgJWISfS3_Ys",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Carregando Dataset a ser usado (MNIST)"
      ]
    },
    {
      "metadata": {
        "id": "JuquHPaD3ehV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RfrjBdqY5qJa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "MNIST é um banco de dados de digitos escritos à mão que usaremsos para treinar e testar nossa rede neural.\n",
        "Esse banco de dados tem algumas limitaações. Por exemplo, não conseguimos abrir o resultado de download em nenhum software de edição de imagens.\n",
        "\n",
        "![alt text](https://github.com/talesmgodois/deep-learning-v2-pytorch/raw/c53f4393f0300d083041068f3e094d3c68be342f/intro-to-pytorch/assets/mnist.png)"
      ]
    },
    {
      "metadata": {
        "id": "uVZQXXWg6-Sj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_imgs(id):\n",
        "  plt.imshow(images[id].numpy().squeeze(), cmap='Greys_r')\n",
        "  \n",
        "dataiter = iter(trainloader)\n",
        "images,labes = next(dataiter)\n",
        "plot_imgs(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o1C8WH_h8Nvv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Vamos rodar nossa rede neural?\n"
      ]
    },
    {
      "metadata": {
        "id": "zm8JoKMh8R4l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "netS = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(images.shape[0], 1, 784)\n",
        "\n",
        "# print(images[0:])\n",
        "ps = netS.forward(images[0,:])\n",
        "\n",
        "# plt.imshow(images[0].view(1,28,28).numpy().squeeze())\n",
        "view_classify(images[0].view(1, 28, 28), ps)\n",
        "print(ps)\n",
        "print(max(ps[0]))\n",
        "print(min(ps[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UqkzoHYu95sE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Hora de treinar essa belezinha\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "4Z_DcGyC99ns",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "netS = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "\n",
        "#Definindo o erro\n",
        "criterion = nn.NLLLoss()\n",
        "print(criterion)\n",
        "\n",
        "#Rodando o método forwaard para pegar os outputs\n",
        "# ps = netS.forward(images[0,:])\n",
        "print(ps)\n",
        "\n",
        "\"\"\"\"\n",
        "  \n",
        "  Definido um otizador, este será responsável por atualizar os pesos com uma taxa de aprendizado( o Alfa lá de trás ) de 0.1\n",
        "  optim.SGD vem de Stochstic Gradient Descent\n",
        "  \n",
        "\"\"\"\n",
        "optimizer = optim.SGD(netS.parameters(), lr=0.01)\n",
        "print(optimizer)\n",
        "\n",
        "\n",
        "#Número de iterações\n",
        "epochs = 2\n",
        "\n",
        "for i in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images, labels in trainloader:\n",
        "    #Mudo o formato de visualização das imagens\n",
        "    images = images.view(images.shape[0], -1)\n",
        "    \n",
        "    #O treino começa a qui pra valer\n",
        "\n",
        "    #zerando o gradient, vamos testar sem essa linha para ver o que acontece\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    #forward no modelo\n",
        "    output = netS.forward(images)\n",
        "#     print(output)\n",
        "    \n",
        "    #Cálculo do erro\n",
        "    loss = criterion(output, labels)\n",
        "\n",
        "    #backPropagation\n",
        "    loss.backward()\n",
        "    \n",
        "    #Atualização dos pesos\n",
        "    optimizer.step()\n",
        "    \n",
        "    #Erro total do dataset\n",
        "    running_loss += loss.item()\n",
        "    \n",
        "  else:\n",
        "    #pra cada for interno vamos calcular a melhora no cálculo do erro\n",
        "    print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2lYqxVgVKO2o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Usando a rede treinada"
      ]
    },
    {
      "metadata": {
        "id": "bn4qBcCyJzGy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = netS.forward(img)\n",
        "\n",
        "# Output of the network are logits, need to take softmax for probabilities\n",
        "ps = torch.exp(logps)\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}